Classical approaches to uncertainty quantification in cognitive modeling rely on computationally expensive resampling of raw trial data, creating barriers for real-time analysis and large-scale studies. We present a computationally efficient bootstrap (CEB) method that operates directly on summary statistics, exploiting the synthetic likelihood structure of the EZ diffusion model. The method uses known sampling distributions of accuracy rate, mean response time, and response time variance to perform a parametric bootstrap, then transforms these resampled statistics through analytical inverse equations to obtain parameter estimates. This transformation-of-variables approach maintains statistical validity while achieving 100--1000 fold speed improvements over full Bayesian methods. We demonstrate the method through two simulation studies: simple parameter recovery and drift regression with design matrices. Results show excellent coverage rates (approximately 95\% for individual parameters) and no systematic bias. We introduce EZAS, an open-source Python package that implements this method along with full Bayesian alternatives. The computationally efficient bootstrap makes real-time uncertainty quantification accessible and enables new applications in adaptive testing, meta-analyses, and exploratory data analysis.
